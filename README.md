## О проекте

Автор: **Сумин Антон Александрович**

Цель данного проекта - продемонстрировать мои навыки программирования,
построения архитектуры приложений, умение разбираться в сторонних библиотеках
и вообще думать головой. Можно считать, что это "пример кода".

В проекте используются следующие сторонние библиотеки:
* cURL
* libxml2
* boost_filesystem
* boost_program_options

На одном из собеседований мне была поставлена следующая тестовая задача (дословно):

> Рабочая версия web-crawler'а: умеет обходить веб-страницы (начиная с какой-то
> стартовой (+ удобнее задать ему фильтр "обходи только страницы, содержащие
> определенную подстроку", чтобы он не разветвлялся слишком сильно))
> до определенной глубины и сохранять их в файловую систему.

При этом на выполнение давалось 8 часов.

За 8 часов мне удалось написать рабочую версию краулера (первый коммит).
Но из-за большой спешки и отсутствия свежего опыта работы как с выбранными сторонними библиотеками, так и с C++ в целом,
пострадали стиль кода, комментирование, не удалось реализовать некоторый интересный функционал.

В данном проекте я привел весь код к единому стилю (опираясь на [рекомендации Google](http://google-styleguide.googlecode.com/svn/trunk/cppguide.html)),
добавил комментарии и доделал желаемый функционал (загрузка в несколько потоков через curl-multi, обработка в несколько тредов).
Это заняло у меня еще порядка 8 часов, но результат получился заметно лучше.
Я уверен, что в проект можно внести еще множество исправлений и улучшений, но в рамках тестового задания решил остановиться на данной версии.
